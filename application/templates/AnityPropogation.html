
{% extends "layout.html" %}
<head>
 {% block head %}
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
.card {
  box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
  transition: 0.3s;
  width: 90%;
}

.card:hover {
  box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
}

.container {
  padding: 2px 16px;
}

.tab-border {
  border: 1px solid #ddd !important;
  border-radius: 4px 4px 0 0;
}

.content-border {
  border: 1px solid #ddd;
  width: 100%;
  height: 650px;
  overflow: scroll;
}

</style>
    {% endblock head %}
</head>

{% block content %}

<div>

<div class="container">
  <h2><b>AFFINITY PROPOGATION</b></h2>
  <br>
  <!-- Nav tabs -->
  <ul class="nav nav-tabs" role="tablist">
  	<li class="nav-item">
      <a class="nav-link tab-border" data-toggle="tab" href="#BASICS">BASICS</a>
    </li>
    <li class="nav-item">
      <a class="nav-link tab-border " data-toggle="tab" href="#USECASES">USECASES</a>
    </li>
    <li class="nav-item">
      <a class="nav-link tab-border" data-toggle="tab" href="#ALGORITHM">ALGORITHM</a>
    </li>
    <li class="nav-item">
      <a class="nav-link tab-border" data-toggle="tab" href="#EXAMPLE">EXAMPLE</a>
    </li>
    <li class="nav-item">
      <a class="nav-link tab-border" data-toggle="tab" href="#ESTIMATORS">ESTIMATORS</a>
    </li>
  </ul>

  <!-- Tab panes -->
  <div class="tab-content">
    <div id="BASICS" class="container tab-pane content-border active"><br>
      <h3>BASICS</h3>
      	<p>AffinityPropagation creates clusters by sending messages between pairs of samples until convergence. A dataset is then described using a small number of exemplars, which are identified as those most representative of other samples. The messages sent between pairs represent the suitability for one sample to be the exemplar of the other, which is updated in response to the values from other pairs. This updating happens iteratively until convergence, at which point the final exemplars are chosen, and hence the final clustering is given.</p>
    </div>
    <div id="USECASES" class="container tab-pane content-border fade"><br>
      <h3>USECASES</h3>
      	<p>Before getting into Logistic Regression understanding following are some of the use cases where this model is used.</p>
		<ul>
			<li>1. Classifying banking customers on whether or not they will default on a loan.</li>
			<li>2. Predicting whether or not a skin lesion is benign or malignant based on some criteria.</li>
			<li>3. Categorizing the mail as spam or not</li>
		</ul>
		<p>Basically this form or analysis will lead to a results of YES or NO.</p>
    </div>
    <div id="ALGORITHM" class="container tab-pane content-border fade"><br>
      <h3>ALGORITHM</h3>
      <p>The messages sent between points belong to one of two categories. The first is the responsibility , which is the accumulated evidence that sample should be the exemplar for sample . The second is the availability which is the accumulated evidence that sample should choose sample to be its exemplar, and considers the values for all other samples that should be an exemplar. In this way, exemplars are chosen by samples if they are (1) similar enough to many samples and (2) chosen by many samples to be representative of themselves.</p>


<p>
  $$S(x) = {1 \over {1 + e^{-x}}}.$$
</p>

<p>Logistic Regression function is as shown below.</p>

<p>
  $$y = {e^{B0+B1x} \over {1 + e^{B0+B1x}}}.$$
</p>

<p>Above is the Logistic Regression function</p>

<ul>
	<li>1) (x) : is input</li>
	<li>2) (B) : is the weights or coefficient values</li>
	<li>3) (y) : Predicted output values</li>
	<li>4) (B0) : is the bias or intercept</li>
	<li>5) (B1) : is the coefficient for the single input value (x)</li>
</ul>
The main difference from linear regression is that output value is being modeled as the binary values (0 or
1) rather numeric value.
<p>Logistic regression is a liner model, but the predictions are using Logistic function, resulting in predictions
being non-linear combination of inputs.This generally happens in Linear regression.</p>

<p>
  $$P(x) = {e^{B0+B1x} \over {1 + e^{B0+B1x}}}.$$
</p>

By applying natural logarithm (ln) on both sides above equation will lead to below format.

<p>
  $$ln({P(x) \over 1 - P(x)}) = B0 + B1x.$$
</p>


<p>Coefficients of the logistic regression algorithm must be estimated from your training data. Maximum-
likelihood estimation is the algorithm which is used to caclulate these coefficients. This is implemented using
Quasi-newton method which is numeric optimization algorithm. This can also be implemented using simpler Gradient descent algorithm</p>
    </div>
    <div id="EXAMPLE" class="container tab-pane content-border fade"><br>
      <h3>EXAMPLE</h3>
      <pre><code class="html">
		x = 5;
		y = 6;
		z = x + y;
		</code></pre>

		<h3>Behaviour</h3>
		This function generally shows its behvaiour as shown below:<br>

		<img src="{{url_for('static', filename='Sigmod.png')}}" alt="" align="middle" width="700" height="400"><br><br>
    </div>
    <div id="ESTIMATORS" class="container tab-pane content-border fade"><br>
      <h3>ESTIMATORS</h3>
      		<h3>Maximum-likelihood estimation</h3>
<p>In statistics Maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical
model. The method obtains the parameter estimates by finding the parameter values that maximize the
liklihood function.</p>

<h3>Quasi-newton method</h3>
<p>Quasi-Newton methods are the methods used to find either zeros or local maxima and minima of functions,
as an alternative to Newton's method. They can be used if the 'Jacobian' or 'Hessian' is unavailable or too
expensive to compute at every iteration.</p>
<h3>Gradient descent algorithm</h3>
<p>Its a first order iterative optimization algorithm for finding the minimum of a function. To find the local
minimum of function using the gradient descent one takes steps proportional to the negative of the gradient
of the function at the current point.</p>
<h3>Physical significance</h3>
<p>F(x) is the multi variable function is defined and differentiable in a neighbourhood of a point a, then F(x)
decreases fast if one goes from a in the direction of the negative gradient of F at a,rF(a). it follows that, if</p>

    </div>
  </div>
</div>







</div>
{% endblock content %}