{% extends "layout_new.html" %}


{% block content %}


<div style="padding-bottom: 2%;">

	<h2 style="font-weight: 800;">CONVOLUTION NEURAL NETWORK INTRODUCTION (CNN)</h2><br><br>

	<div class="card" style="height: 100%; width: 90%; margin: auto; padding-bottom: 2%; padding-left: 2%;
    padding-right: 2%;padding-top: 2%;" >
	  <!-- <img src="img_avatar.png" alt="Avatar" style="width:100%"> -->
	  
	  <table style="width:100%">
		<tr>
			<td valign="top" style="width: 50%; ">
			<div style="padding-right: 3%;">


	  <h4 style="font-weight: 900;">BACK GROUND </h4>
	  <hr><br>

		<table style="width:100%">
			<tr>
			  <td><b>1956 &ensp;</b></td>
			  <td><b>Neural network</b> based computations machines</td>
			  <td><b><a href="https://en.wikipedia.org/wiki/Nathaniel_Rochester_(computer_scientist)">Rochester</a>, Holland, Habit, Duda</b></td>
			</tr>
			<tr>
			  <td><b>1958 &ensp;</b></td>
			  <td><b>First perceptron</b> for pattern recognition</td>
			  <td><b><a href = "https://en.wikipedia.org/wiki/Frank_Rosenblatt">Rosenblatt</a> </b></td>
			</tr>
			<tr>
			  <td><b>1959 &ensp;</b></td>
			  <td>A biological model proposed with <b>simple and complex cell</b></td>
			  <td><b><a href="https://en.wikipedia.org/wiki/David_H._Hubel">Hubel</a> 
			  </a>and <a href="https://en.wikipedia.org/wiki/Torsten_Wiesel">Wiesel</a> (Nobel laureates)</b></td>
			</tr>
			<tr>
				<td><b>1965 &ensp;</b></td>
				<td>First <b>functional networks</b> with many layers was published</td>
				<td><b><a href ="https://en.wikipedia.org/wiki/Alexey_Ivakhnenko">Ivakhnenko</a> and Lapa</b></td>
			  </tr>
		  </table>
	<br><br>
	Research stagnated due to 
	<ol>
		<li> Perceptron is in-capable to process the exclusive-or circuit </li>
		<li> Processing power was an issue to handle large neural networks</li>
	</ol>
	<br><br>
	<table style="width:100%">
		<tr>
		  <td><b>1975 &ensp;</b></td>
		  <td> Backpropogation, distributed error and adjusted weights at each node</td>
		  <td><b><a href ="https://en.wikipedia.org/wiki/Paul_Werbos">Werbos</a></b></td>
		</tr>
		<tr>
		  <td><b>1986 &ensp;</b></td>
		  <td>Parallel and distributed computing used to simulate Neural networks</td>
		  <td><b><a href="https://en.wikipedia.org/wiki/David_Rumelhart">Rumelhart</a> 
			and <a href="https://en.wikipedia.org/wiki/James_McClelland_(psychologist)">McClelland</a> </b></td>
		</tr>
		<tr>
		  <td><b>1988 &ensp;</b></td>
		  <td>CNN was developed with biological inspired image reconition model</td>
		  <td><b><a href ="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoffrey Hinton</a> 
			and <a href="https://en.wikipedia.org/wiki/Yann_LeCun">Yann LeCun</a></b></td>
		</tr>
		<tr>
			<td><b>2006 &ensp;</b></td>
			<td>Proposed stacking of multiple layers, to learn high level representaion</td>
			<td><b><a href ="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoffrey Hinton</a></b></td>
		  </tr>
		  <tr>
			<td><b>2012 &ensp;</b></td>
			<td>Cats and dogs classificatoin with high level learning system </td>
			<td><b><a href ="https://en.wikipedia.org/wiki/Andrew_Ng">Andrew Ng</a> 
				and <a href="https://en.wikipedia.org/wiki/Jeff_Dean_(computer_scientist)">Jeff Dean</a></b></td>
		  </tr>
	  </table>
	<br><br>
	</div>
	</td>
	<td valign="top">
		<div>
			<div style="height: 40%; " class = "vertical"></div> 
		</div>
	</td>
	  <td style="width: 50%; padding-left: 1.5%;">
		<div style="padding-right: 3%;">
			<h4 style="font-weight: 900;">TERMINOLOGY & DEFINITIONS</h4>
			<hr><br>
		<h5 style="font-weight: 900;">TERMINOLOGY</h5>
			<ol>
		  <li>Neurons </li>
		  <li>Layers</li>
		  <li>Activation function</li>
		  <li>Back Propogation</li>
	  </ol>
	  <br><br>
		<h5 style="font-weight: 900;">DEFINITIONS</h5>
		<ul>
			<li><p><b><u>Neurons:</u></b> These are the circuits which help process and transmit the data to next Layers</p></li>
			<li><p><b><u>Layers:</u></b> These are the combinations of the group of neurons which can connected together in a particular fashion</p></li>
			<li><p><b><u>Activation function:</u></b> This is the non-linear funciton which will add the bias component to the system</p></li>
			<li><p><b><u>Back Propogation:</u></b> This is the mechanism using which the error is calculated and the weigths are adjusted so that 
				network learns the features based on its mistakes</p></li>
		</ul>
	</div>
		</td>
	  </tr>
	</table>
	  <!-- <img src="{{url_for('static', filename='classifier_info.png')}}" alt="" align="middle" style="width:100%"> -->
	  <!-- <div class="container">
		<h4><b>John Doe</b></h4> 
		<p>Architect & Engineer</p> 
	  </div> -->
	</div>




</div>
{% endblock content %}